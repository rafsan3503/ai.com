<!doctype html>
<html lang=en>

<head>
    <meta charset=utf-8>
    <meta content="width=device-width,initial-scale=1" name=viewport>
    
    
    
    <link
        href="https://fonts.googleapis.com/css2?&family=Nunito:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;0,1000;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900;1,1000&display=swap"
        rel=stylesheet>
    <link href="dac32d1a8f621c4e2845f62d9670a3fd.png" rel=icon type=image/svg+xml>
    <title>Announcing AI.Com</title>
    <link href=https://fonts.googleapis.com rel=preconnect>
    <link crossorigin href=https://fonts.gstatic.com rel=preconnect>
    <link as=image href=https://x.ai/bg_square_large.webp rel=preload>
    <link as=image href=https://x.ai/bg_square_small.webp rel=preload>
    <link href=https://x.ai/styles.css rel=stylesheet>

<body>
    <div class=stars>
        <div class="animation stars-small"></div>
        <div class="animation stars-large"></div>
    </div>
    <header id=header>
        <div class=background></div>
        <div class=container>
            <div class=content>
                <a href=https://x.ai /><img alt="xAI Logo" src="./dac32d1a8f621c4e2845f62d9670a3fd.png" style="background-color: aliceblue;"></a>
                <nav>
                    <a class=active href=https://x.ai /> Telegram</a>
                    <a href=/about /> Twitter</a>
                    <a href=/career /> Dextools
                    </a>
                    <a href=/prompt-ide /> Uniswap</a></nav>
            </div>
        </div>
    </header>
    <div id=swup>
        <section class="page-teaser models">
            <div class=gradient></div>
            <div class=container>
                <div class=hero>
                    <h1 class=animated><span>Introducing </span> <span>AI.com</span></h1>
                </div>
            </div>
        </section>
        <section class=page>
            <div class=container>
                <div class=page-content>
                    <p><small>November 15, 2023</small>
                    <p><i>Elon Musk’s new AI startup xAI now redirects to the <a href="https://ai.com" target="_blank">AI.com</a> domain, which just recently was the home of OpenAI's ChatGPT.
                    <a href="https://ai.com" target="_blank">AI.com</a> now sends users to a page announcing xAI. The site outlines the new startup’s formation. No confirmation has been
                    given by either Musk or X (formerly Twitter) that a deal for the domain took place. OpenAI had only purchased the domain
                    from Google some five months prior. No official amount of how much OpenAI paid for the domain was disclosed. However,
                    speculation online pointed to a sum of $11 million. XAI also uses the domain x.ai. Dynadot is listed as the registrar
                    for the domain, with x.ai registered since December 2017. WHOIS data on the domain only reveals the owners as being
                    based in San Mateo, some 20 minutes away from the X headquarters in San Francisco. Who owns <a href="https://ai.com" target="_blank">AI.com</a>?
                        </i>
                    <h2 id=why-we-are-building-grok>Who owns <a href="https://ai.com" target="_blank">AI.com</a>?</h2>
                    <p>Will someone please tell us who the hell owns <a href="https://ai.com" target="_blank">AI.com</a> and what they're doing with it?
                    The domain, which used to direct to ChatGPT, now redirects users to xAI, an AI company owned by Elon Musk. Separate from
                    X Corp, xAI claims on its website that it "will work closely with X," the social media company formerly known as Twitter
                    — including using posts on X as training for its large language model. The high-value <a href="https://ai.com" target="_blank">AI.com</a> domain name changed hands
                    in 2021, sat idle for a while, and then suddenly started redirecting to ChatGPT in February. For ChatGPT users, it was a
                    helpful shortcut if they didn't have the site bookmarked and couldn't quite remember the precise URL for the chatbot
                    (chat.open<a href="https://ai.com" target="_blank">AI.com</a>, for the record). To be clear, Saw.com never directly claimed that OpenAI was the buyer, and this
                    change certainly calls that possibility into question — but it also creates a mystery: Did someone pay millions for a
                    domain name out of sheer enthusiasm for ChatGPT, and then experience a shift in loyalty? Could it be that the owner
                    really is OpenAI, and it was hacked? Or did Elon Musk just go ahead and write a big, fat check for the domain name on a
                    lark, like that time he suddenly threw a famous social media brand into the woodchipper of history?
                    
                    
                    
                    <p><strong>Total Supply</strong>: There are a total supply of 6,900,000,000 <a href="https://ai.com" target="_blank">AI.com</a> tokens in circulation
                    <p><strong>Taxes</strong>: <a href="https://ai.com" target="_blank">AI.com</a> is a zero tax token, meaning there are taxes when buying or selling tokens
                    <p><strong>Liquidity</strong>: Burned
                    <p><strong>Contract</strong>: Renounced
                    <!-- <div class=table-wrapper>
                        <table class=table>
                            <thead>
                                <tr>
                                    <th>Benchmark
                                    <th>Grok-0 (33B)
                                    <th>LLaMa 2 70B
                                    <th>Inflection-1
                                    <th>GPT-3.5
                                    <th><b>Grok-1</b>
                                    <th>Palm 2
                                    <th>Claude 2
                                    <th>GPT-4
                            <tbody>
                                <tr>
                                    <th scope=row>GSM8k
                                    <td>56.8%<br><span class=info>8-shot</span>
                                    <td>56.8%<br><span class=info>8-shot</span>
                                    <td>62.9%<br><span class=info>8-shot</span>
                                    <td>57.1%<br><span class=info>8-shot</span>
                                    <td>62.9%<br><span class=info>8-shot</span>
                                    <td>80.7%<br><span class=info>8-shot</span>
                                    <td>88.0%<br><span class=info>8-shot</span>
                                    <td>92.0%<br><span class=info>8-shot</span>
                                <tr>
                                    <th scope=row>MMLU
                                    <td>65.7%<br><span class=info>5-shot</span>
                                    <td>68.9%<br><span class=info>5-shot</span>
                                    <td>72.7%<br><span class=info>5-shot</span>
                                    <td>70.0%<br><span class=info>5-shot</span>
                                    <td>73.0%<br><span class=info>5-shot</span>
                                    <td>78.0%<br><span class=info>5-shot</span>
                                    <td>75.0%<br><span class=info>5-shot + CoT</span>
                                    <td>86.4%<br><span class=info>5-shot</span>
                                <tr>
                                    <th scope=row>HumanEval
                                    <td>39.7%<br><span class=info>0-shot</span>
                                    <td>29.9%<br><span class=info>0-shot</span>
                                    <td>35.4%<br><span class=info>0-shot</span>
                                    <td>48.1%<br><span class=info>0-shot</span>
                                    <td>63.2%<br><span class=info>0-shot</span>
                                    <td>-
                                    <td>70%<br><span class=info>0-shot</span>
                                    <td>67%<br><span class=info>0-shot</span>
                                <tr>
                                    <th scope=row>MATH
                                    <td>15.7%<br><span class=info>4-shot</span>
                                    <td>13.5%<br><span class=info>4-shot</span>
                                    <td>16.0%<br><span class=info>4-shot</span>
                                    <td>23.5%<br><span class=info>4-shot</span>
                                    <td>23.9%<br><span class=info>4-shot</span>
                                    <td>34.6%<br><span class=info>4-shot</span>
                                    <td>-
                                    <td>42.5%<br><span class=info>4-shot</span>
                        </table>
                    </div>
                    <p>On these benchmarks, Grok-1 displayed strong results, surpassing all other models in its compute
                        class, including ChatGPT-3.5 and Inflection-1. It is only surpassed by models that were trained
                        with a significantly larger amount of training data and compute resources like GPT-4. This
                        showcases the rapid progress we are making at xAI in training LLMs with exceptional efficiency.
                    <p>Since these benchmarks can be found on the web and we can’t rule out that our models were
                        inadvertently trained on them, we hand-graded our model (and also Claude-2 and GPT-4) on the
                        2023 <a
                            href=https://dload-oktatas.educatio.hu/erettsegi/feladatok_2023tavasz_kozep/k_matang_23maj_fl.pdf>Hungarian
                            national high school finals in mathematics</a>, which was published at the end of May, after
                        we collected our dataset. Grok passed the exam with a C (59%), while Claude-2 achieved the same
                        grade (55%), and GPT-4 got a B with 68%. All models were evaluated at temperature 0.1 and the
                        same prompt. It must be noted that we made no effort to tune for this evaluation. This
                        experiment served as a “real-life” test on a dataset our model was never explicitly tuned for.
                    <div class=table-wrapper>
                        <table class=table>
                            <thead>
                                <tr>
                                    <th>Human-graded evaluation
                                    <th>Grok-0
                                    <th>GPT-3.5
                                    <th>Claude 2
                                    <th><b>Grok-1</b>
                                    <th>GPT-4
                            <tbody>
                                <tr>
                                    <th scope=row>Hungarian National High School Math Exam (May 2023)
                                    <td>37%<br><span class=info>1-shot</span>
                                    <td>41%<br><span class=info>1-shot</span>
                                    <td>55%<br><span class=info>1-shot</span>
                                    <td>59%<br><span class=info>1-shot</span>
                                    <td>68%<br><span class=info>1-shot</span>
                        </table>
                    </div>
                    <p>We provide a summary of the important technical details of Grok-1 in the <a
                            href=https://x.ai/model-card />model card</a>.
                    <h2 id=engineering-at-xai>Engineering at xAI</h2>
                    <p>At the frontier of deep learning research, reliable infrastructure must be built with the same
                        care as datasets and learning algorithms. To create Grok, we built a custom training and
                        inference stack based on Kubernetes, Rust, and JAX.
                    <p>LLM training runs like a freight train thundering ahead; if one car derails, the entire train is
                        dragged off the tracks, making it difficult to set upright again. There are a myriad of ways
                        GPUs fail: manufacturing defects, loose connections, incorrect configuration, degraded memory
                        chips, the occasional random bit flip, and more. When training, we synchronize computations
                        across tens of thousands of GPUs for months on end, and all these failure modes become frequent
                        due to scale. To overcome these challenges, we employ a set of custom distributed systems that
                        ensure that every type of failure is immediately identified and automatically handled. At xAI,
                        we have made maximizing useful compute per watt the key focus of our efforts. Over the past few
                        months, our infrastructure has enabled us to minimize downtime and maintain a high Model Flop
                        Utilization (MFU) even in the presence of unreliable hardware.
                    <p>Rust has proven to be an ideal choice for building scalable, reliable, and maintainable
                        infrastructure. It offers high performance, a rich ecosystem, and prevents the majority of bugs
                        one would typically find in a distributed system. Given our small team size, infrastructure
                        reliability is crucial, otherwise, maintenance starves innovation. Rust provides us with
                        confidence that any code modification or refactor is likely to produce working programs that
                        will run for months with minimal supervision.
                    <p>We are now preparing for our next jump in model capabilities, which will require reliably
                        coordinating training runs on tens of thousands of accelerators, running internet-scale data
                        pipelines, and building new kinds of capabilities and tools into Grok. If that sounds exciting
                        to you, apply to join the team <a href=https://x.ai/career />here</a>.
                    <h2 id=research-at-xai>Research at xAI</h2>
                    <p>We give Grok access to search tools and real-time information, but as with all the LLMs trained
                        on next-token prediction, our model can still generate false or contradictory information. We
                        believe that achieving reliable reasoning is the most important research direction to address
                        the limitations of current systems. Here, we would like to highlight a few promising research
                        directions we are most excited about at xAI:
                    <ul>
                        <li><strong>Scalable oversight with tool assistance.</strong> Human feedback is essential.
                            However, providing consistent and accurate feedback can be challenging, especially when
                            dealing with lengthy code or complex reasoning steps. AI can assist with scalable oversight
                            by looking up references from different sources, verifying intermediate steps with external
                            tools, and seeking human feedback when necessary. We aim to make the most effective use of
                            our <a href=https://boards.greenhouse.io/xai/jobs/4101903007>AI tutors'</a> time with the
                            help of our models.
                        <li><strong>Integrating with formal verification for safety, reliability, and
                                grounding.</strong> To create AI systems that can reason deeply about the real world, we
                            plan to develop reasoning skills in less ambiguous and more verifiable situations. This
                            allows us to evaluate our systems without human feedback or interaction with the real world.
                            One major immediate goal of this approach is to give formal guarantees for code correctness,
                            especially regarding formally verifiable aspects of AI safety.
                        <li><strong>Long-context understanding and retrieval.</strong> Training models for efficiently
                            discovering useful knowledge in a particular context are at the heart of producing truly
                            intelligent systems. We are working on methods that can discover and retrieve information
                            whenever it is needed.
                        <li><strong>Adversarial robustness.</strong> Adversarial examples demonstrate that optimizers
                            can easily exploit vulnerabilities in AI systems, both during training and serving time,
                            causing them to make egregious mistakes. These vulnerabilities are long-standing weaknesses
                            of deep learning models. We are particularly interested in improving the robustness of LLMs,
                            reward models, and monitoring systems.
                        <li><strong>Multimodal capabilities.</strong> Currently, Grok doesn’t have other senses, such as
                            vision and audio. To better assist users, we will equip Grok with these different senses
                            that can enable broader applications, including real-time interactions and assistance.
                    </ul>
                    <p>We believe that AI holds immense potential for contributing significant scientific and economic
                        value to society, so we will work towards developing reliable safeguards against catastrophic
                        forms of malicious use. We believe in doing our utmost to ensure that AI remains a force for
                        good.
                    <p>If you share our optimism and want to contribute to our mission, apply to join the team <a
                            href=https://x.ai/career />here</a>. -->
                    <h2 id=early-access-to-grok>Community</h2>
                    <p>AI.COM is dedicated to ensuring a safe and profitable project for its amazing community of investors.
                </div>
            </div>
        </section>
    </div>
    <footer>
        <div class=container>
            <div class=footer-content><img alt="xAI Logo" src="./dac32d1a8f621c4e2845f62d9670a3fd.png" style="background-color: white;">
                <div class=left><a href=https://x.com/xai>AI.Com</a> © 2023<br> All rights reserved.</div>
                <div class=right><a> Unlock the Mystery.</a><br></div>
            </div>
        </div>
    </footer>
    <script [data-swup-ignore-script] src=https://x.ai/main.js></script>